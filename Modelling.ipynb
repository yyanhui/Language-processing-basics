{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e17361-0d1a-4481-be04-24f529a073b6",
   "metadata": {},
   "source": [
    "The language models deal with input of vectors embedded which have arbitrary length, the objective will be dependant on the history information, neural networks accept fixed size of inputs, so we need to deal with context and history size. one way of modeling is to input only a fixed window of history. The introduction of encoders and decoders:\n",
    "\n",
    "Encoders : Send input through a smaller-than-necessary layer to force the neural network to find a small set of parameters that produced intermediate activations that approximates the output\n",
    "\n",
    "Decoder : A set of parameters that recovers information to produce the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e07707-e9f6-4b56-b6a4-3b5105adae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the text file\n",
    "with open('Europarl-french-v7/europarl-en.txt', 'r') as file:\n",
    "    lines_en = file.readlines()[:5000]\n",
    "with open('Europarl-french-v7/europarl-fr.txt', 'r') as file:\n",
    "    lines_fr = file.readlines()[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f287f3cc-e3a9-48ca-bee1-2d631a8848fa",
   "metadata": {},
   "source": [
    "## RNN and LSTM\n",
    "RNN structures : deal with different length of history, recurrently process each time slice\n",
    "![RNN](RNN.png)\n",
    "\n",
    "LSTM : instead of replacing the hidden state each time-slice, adding a memory cell to decide which part to forget or memmorize\n",
    "![LTSM](LSTM.png)\n",
    "\n",
    "a. forget gate : $f = \\sigma(W_{x,f}x+b_{x,f}+W_{h,f}h+b_{h,f}) $ output (0,1)\n",
    "\n",
    "b. input gate : $i = \\sigma(W_{x,i}x+b_{i,f}+W_{h,i}h+b_{h,i}) $ \n",
    "\n",
    "c. cell memory : $g = tanh(W_{x,g}x+b_{x,g}+W_{h,g}h+b_{h,g}) $  output range [-1,1]\n",
    "\n",
    "d. update cell state : $c = (f*c_{i-1})+(i*g)$\n",
    "\n",
    "e. output gate :  $o = \\sigma(W_{x,o}x+b_{x,o}+W_{h,o}h+b_{h,o}) $ \n",
    "\n",
    "f. update hidden state: $h_i = o*tanh(c_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3e95975-f461-4ce5-b7a0-2550d079eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Create input sequences and labels for training\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "input_sequences = []\n",
    "for line in lines_en[:500]:\n",
    "    token_list = tokenizer.encode(line.replace(\"\\n\", \"\")[:512])\n",
    "    input_sequences.append(token_list[:-2])\n",
    "\n",
    "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=tokenizer.vocab_size)\n",
    "X_ = X.reshape((X.shape[0], 1, X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4305543a-da8e-470c-9e70-9ad3e8da0f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 104)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "329aaffd-2186-4743-a727-5a420bbf7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 28996)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7e99b92-b0de-44d4-86f6-137a6360d993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x309619fd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train the SimpleRNN model\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(100, input_shape=(1, X_.shape[2])))\n",
    "model_rnn.add(Dense(tokenizer.vocab_size, activation='softmax'))\n",
    "model_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_, y, epochs=100, verbose=0)\n",
    "\n",
    "# Build and train the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(100, input_shape=(1, X_.shape[2])))\n",
    "model_lstm.add(Dense(tokenizer.vocab_size, activation='softmax'))\n",
    "model_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.fit(X_, y, epochs=100, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8498e2f-e8e7-4d7d-8c77-b4dc2b840df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Generated Text (SimpleRNN): There should be no confusion in this debate. As environmentalists, we do not want an programmes employment them ##ity report\n",
      "Generated Text (LSTM): There should be no confusion in this debate. As environmentalists, we do not want an safety Europe them citizens Europe\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained models\n",
    "def generate_text(seed_text, model, max_sequence_len, num_words):\n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.encode(seed_text)\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        token_list = token_list.reshape((token_list.shape[0], 1, token_list.shape[1]))\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = tokenizer.decode(predicted)\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Example of generating text with each model\n",
    "generated_text_rnn = generate_text(\"There should be no confusion in this debate. As environmentalists, we do not want an\", model_rnn, max_sequence_length, num_words=5)\n",
    "generated_text_lstm = generate_text(\"There should be no confusion in this debate. As environmentalists, we do not want an\", model_lstm, max_sequence_length, num_words=5)\n",
    "\n",
    "print(\"Generated Text (SimpleRNN):\", generated_text_rnn)\n",
    "print(\"Generated Text (LSTM):\", generated_text_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430984c2-68fd-4cf5-a425-e871fec12722",
   "metadata": {},
   "source": [
    "## Sequence to Sequence models\n",
    "When dealing with translation tasks, the input and output will look like\n",
    "\n",
    "$input_i = SOSx_{i,1}x_{i,2}\\dots x_{i,2}EOS$\n",
    "\n",
    "$ouput_i = SOSy_{i,1}y_{i,2}\\dots y_{i,2}EOS$\n",
    "\n",
    "there's no one-to-one mapping, the output could be of arbitrary length, the entire context is needed for translation.\n",
    "\n",
    "Then a sequence to sequence model structure is utilized, it encodes all the words until EOS reached, then after decoding all words, there's a encoding layer to put all results together\n",
    "![s2s](s2s.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c199d2b-3b9c-475f-9649-3ec57d40ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf8bc333-36d8-4e87-b1e1-2ecca4758790",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 16  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 1000  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "997ac799-c57b-4e96-8142-fdea9cd9eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1000\n",
      "Number of unique input tokens: 86\n",
      "Number of unique output tokens: 99\n",
      "Max sequence length for inputs: 683\n",
      "Max sequence length for outputs: 877\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for i in range(num_samples):\n",
    "    input_text = lines_en[i]\n",
    "    target_text = lines_fr[i]\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65a922e2-3cd9-4f7e-ae16-26183ae06ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82680a1d-8762-44f5-918b-b025acb48363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4238ca01-375a-4e92-9059-61f920d846d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.6275 - loss: 2.6168 - val_accuracy: 0.8410 - val_loss: 0.9426\n",
      "Epoch 2/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8151 - loss: 1.0525 - val_accuracy: 0.8409 - val_loss: 0.9267\n",
      "Epoch 3/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8183 - loss: 1.0300 - val_accuracy: 0.8409 - val_loss: 0.8873\n",
      "Epoch 4/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8169 - loss: 1.0070 - val_accuracy: 0.8409 - val_loss: 0.8595\n",
      "Epoch 5/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8182 - loss: 0.9703 - val_accuracy: 0.8405 - val_loss: 0.9735\n",
      "Epoch 6/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8213 - loss: 0.9795 - val_accuracy: 0.8409 - val_loss: 0.7349\n",
      "Epoch 7/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8169 - loss: 0.9208 - val_accuracy: 0.8407 - val_loss: 0.7991\n",
      "Epoch 8/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8141 - loss: 0.8940 - val_accuracy: 0.8404 - val_loss: 0.6042\n",
      "Epoch 9/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8155 - loss: 0.7221 - val_accuracy: 0.8408 - val_loss: 0.9141\n",
      "Epoch 10/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8228 - loss: 0.8052 - val_accuracy: 0.8405 - val_loss: 0.5939\n",
      "Epoch 11/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8189 - loss: 0.6609 - val_accuracy: 0.8339 - val_loss: 0.6076\n",
      "Epoch 12/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8103 - loss: 0.9425 - val_accuracy: 0.8405 - val_loss: 0.5868\n",
      "Epoch 13/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8163 - loss: 0.6757 - val_accuracy: 0.8405 - val_loss: 0.5785\n",
      "Epoch 14/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8134 - loss: 0.6801 - val_accuracy: 0.8406 - val_loss: 0.5760\n",
      "Epoch 15/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8135 - loss: 0.6676 - val_accuracy: 0.8332 - val_loss: 0.5806\n",
      "Epoch 16/16\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8113 - loss: 0.7723 - val_accuracy: 0.8390 - val_loss: 0.5860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x32db1e9c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "# model.save(\"s2s_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40668421-3b25-40a4-809f-6a74d18d5598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Are state aid to business or inter-company agreements legitimate in a market economy, and who must supervise these exceptions to the absolute rules of the market economy?\n",
      "\n",
      "Decoded sentence: eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "## translation with this model\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "# Take one sequence \n",
    "# for trying out decoding.\n",
    "input_seq = encoder_input_data[num_samples - 1:num_samples]\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(\"-\")\n",
    "print(\"Input sentence:\", input_texts[num_samples - 1])\n",
    "print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2a9a9-609f-4e7c-8bb9-c22836a0a008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
